
    rm -Rf
    history



1. commandes maven

    création d'un artefact
    ------------------------
    mvn archetype:generate -DgroupId=com.luchocorp.eventstreams -DartifactId=KFKevents -DarchetypeArtifactId=maven-archetype-quickstart -DarchetypeVersion=1.4 -DinteractiveMode=false

    construction du projet
    ----------------------
    mvn install

    execution du projet
    -------------------
    cd ~/workspace/java/KFKevents
    java -cp target/KFKevents-1.0-SNAPSHOT.jar com.luchocorp.eventstreams.App

2. Kafka

    Installation Kafka
    ------------------
    > wget http://www-us.apache.org/dist/kafka/2.7.0/kafka_2.13-2.7.0.tgz
    > tar xzf kafka_2.13-2.7.0.tgz
    > mv kafka_2.13-2.7.0 /usr/local/kafka

    create a systemd unit file for Zookeeper
    ----------------------------------------
    > sudo vi /etc/systemd/system/zookeeper.service

    create a systemd unit file for the Kafka service
    ------------------------------------------------
    > sudo vi /etc/systemd/system/kafka.service

    Reload the systemd daemon to apply new changes
    ----------------------------------------------
    > sudo systemctl daemon-reload

    start the Kafka server and view the running status
    --------------------------------------------------
    > sudo systemctl start kafka
    > sudo systemctl status kafka

    Create a Topic in Kafka
    -----------------------
    Kafka provides multiple pre-built shell script to work on it. First, create a topic named “testTopic” with a single partition with single replica:

    > cd /usr/local/kafka
    > bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic testTopic

    see the created topics on Kafka by the running below command:
    
    > bin/kafka-topics.sh --list --zookeeper localhost:2181

    Send and Receive Messages in Kafka
    ----------------------------------
    The “producer” is the process responsible for put data into our Kafka. The Kafka comes with a command-line client that will take input from a file or from standard input and send it out as messages to the Kafka cluster. The default Kafka sends each line as a separate message.
    Let’s run the producer and then type a few messages into the console to send to the server.

    > bin/kafka-console-producer.sh --broker-list localhost:9092 --topic testTopic
    > Welcome to kafka
    > This is my first topic
    >

    You can exit this command or keep this terminal running for further testing. Now open a new terminal to the Kafka consumer process on the next step.

    Using Kafka Consumer
    --------------------
    Kafka also has a command-line consumer to read data from the Kafka cluster and display messages to standard output.

    > bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic testTopic --from-beginning
      Welcome to kafka
      This is my first topic

      Now, If you have still running Kafka producer (Step #6) in another terminal. Just type some text on that producer terminal. it will immediately visible on consumer terminal.





